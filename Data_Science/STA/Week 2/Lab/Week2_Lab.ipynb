{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd918a-45e8-4275-adc1-1033a9b2f4eb",
   "metadata": {},
   "source": [
    "# Week 2 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a710cfc-e13f-4ae9-8a0c-2576db903a50",
   "metadata": {},
   "source": [
    "This notebook includes all the code snippets in the lab notes for Week 2, asz copying-and-pasting from the PDF often fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce422b39-21de-4793-972e-d2b3cb20cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries we'll use\n",
    "######################################\n",
    "\n",
    "# Basic numerics\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress certain irrelevant warnings generated by the graphics libraries\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "# Statistical modelling tools\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d674f-830c-4317-817e-19531e84fb25",
   "metadata": {},
   "source": [
    "## Read the earthquake data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8824b-8747-4b3e-a082-56d704d18771",
   "metadata": {},
   "source": [
    "Look at the full dataset `df` and try to understand the meaning of the various columns (in theory the dataset should be accompanied by an explanation of what it contains). Can you spot any missing data?\n",
    "\n",
    "You do not have to write anything now, but think of what you would write if you had to produce a report about these data. Also, imagine standing up in front of an audience to present an inroductory analysis. What would you point out about these data? And what would you say about the methods you are going to use next to study this data? Take inspiration from the slides in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00eb1a-702b-410c-bede-fdfbeee473b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('earthquakes_US_14Jul-13Aug_2018.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1ae6e-9ab2-437f-a5f7-f71724768532",
   "metadata": {},
   "source": [
    "## Visualise the distribution of the magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a54165-1a23-4787-8cc7-6ffbce6e9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data for magnitudes into an array\n",
    "x = df.mag.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916d0b9-6062-413f-b261-75e7647224f9",
   "metadata": {},
   "source": [
    "No matter which software you use, think about having to explain someone else which visualisation is lossless or lossy, and why. Also, this is often overlooked, especially when you are in a hurry, but ensure all your graphs have **titles**, **labels on the axes** and if need be, **keys** or **legends** to explain  plotting conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c384cd-2f6f-4303-ad8a-51275c0dea49",
   "metadata": {},
   "source": [
    "#### Seaborn's `displot()`\n",
    "\n",
    "Run the command `sns.displot( x )` and look at the result. In which ways does it differ from the graph\n",
    "produced in the lecture slides? Check the code in `earth.ipynb` to see how to customise your plot and what the different lines of code do.\n",
    "\n",
    "Explore the way that `displot()` works: there's a helpful\n",
    "[tutorial](https://seaborn.pydata.org/tutorial/distributions.html) provided by Seaborn's developers. Play around with the parameters, for example changing the number of bins using `bins = 8`, or specifying the bin edges, to achieve unequal bin sizes (e.g. `bins = [0,0.5,2,5]`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90b308-f4fc-4c1c-976d-db32771c3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "sns.displot( x )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175fc826-7040-4355-86e0-cf0b11890d12",
   "metadata": {},
   "source": [
    "One can also use `displot()` to combine a rug plot, histogram and the kernel density plot in a single figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b0408-e041-4807-acf0-b004afb9fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot( x, kde=True, rug=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7725281-35d6-492a-9166-d406f951aad5",
   "metadata": {},
   "source": [
    "How would you do a jitter plot in Python? There is a related example in the notebook for Week&nbsp;1's analysis of the data from Two Truths and a Lie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401727f-6775-4eb8-b38b-c2056134e25d",
   "metadata": {},
   "source": [
    "#### Working with histograms using `NumPy` and `Matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb56c8-eaf1-476a-97e2-682d1979430c",
   "metadata": {},
   "source": [
    "Another, more flexible alternative to plot the histogram is to find the $x$- and $y$-values that specify the bars with the command \n",
    "\n",
    "`yh,xh = np.histogram(x,n,density=True)`, \n",
    "\n",
    "where `x` is the data and `n` is the number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12e1d3-ded6-4337-9239-5e1ff0bdbefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting bin heights and boundaries with NumPy's histogram() function\n",
    "n = 50 # number of bins\n",
    "yh,xh = np.histogram(x,n,density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074b24b-4b09-4f71-8bef-cfdaec4edac8",
   "metadata": {},
   "source": [
    "What does the vector `xh` contain? How long is it? What does `yh` contain? How long is it? Why do you think they are not of the same length? To make them of the same length you will have to add an extra value to the `yh` vector using the function `np.concatenate((vector1,vector2))`, which is documented [here](https://numpy.org/doc/1.25/reference/generated/numpy.concatenate.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc021503-2f84-492c-b580-499a77cd1917",
   "metadata": {},
   "source": [
    "To plot only the &ldquo;outline&rdquo; of the histogram (useful if you want to plot two or more histograms on top of each other), use the function `plt.step()`, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd05cc-f175-45e1-ac57-f8e2525fb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the outline of the histogram\n",
    "plt.step(xh,np.concatenate(([0.],yh)),'b',linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a578a-441d-4212-a921-5fa537e08901",
   "metadata": {},
   "source": [
    "In these histograms, what does `density=True` do? Try computing `np.sum(yh)`: why is it not equal to 1? Try `density=False`: what are the values of `yh` now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0369b9c-4819-4b5d-8a23-5a284087b88b",
   "metadata": {},
   "source": [
    "#### Draw a KDE using tools from `statsmodels`\n",
    "\n",
    "For more flexibility in plotting the kernel density and to be able to choose different kernels we use\n",
    "the following commands, where the first line initializes a univariate kernel density estimator and the second computes the values of the fitted kernel at many points on the $x$-axis (the option `fft` needs to be `False`, except for in the case of the Gaussian kernel). Other kernel options are `tri` for the triangular and `gau` for the Gaussian one.\n",
    "\n",
    "Here again, the developers have provided a helpful\n",
    "[tutorial](https://docs.w3cub.com/statsmodels/examples/notebooks/generated/kernel_density/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e018e-511c-48d3-9cc8-27f15da59fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x and y coords of a KDE (with uniform kernel) using tools from statsmodels\n",
    "mykdeu = sm.nonparametric.KDEUnivariate(x) \n",
    "mykdeu.fit(kernel=\"uni\",fft=False) \n",
    "xu = mykdeu.support \n",
    "yu = mykdeu.density \n",
    "plt.plot(xu,yu,'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d0ff0-95af-42f1-925c-883028481799",
   "metadata": {},
   "source": [
    "Finally, play with different numerical values for the option bw, the width of the kernel. For example, try overlaying in different colours the kernel densities obtained for values of `bw` from the list `[0.02,0.05,0.2,0.5,2]`. Which values do you think are &lsquo;sensible&rsquo;?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36154b-a4f7-40ad-92fa-9b76e948bac2",
   "metadata": {},
   "source": [
    "## Measures of central tendency and higher moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7565a664-6199-450e-a2fd-4c468bb2e52f",
   "metadata": {},
   "source": [
    "One can compute the mean and median with the functions `np.mean()` and `np.median()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d1718-f644-44e3-8194-1f403dd9b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(x), np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e276671f-0b21-4812-8ec3-de7e3dd843d8",
   "metadata": {},
   "source": [
    "The most difficult measure of central tendency to compute is the mode because it is estimated from the kernel density estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a606e-4c40-48aa-b873-ffa1853c9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating the mode with a KDE\n",
    "mykde = sns.kdeplot(x,color='black') \n",
    "xm,ym = mykde.get_lines()[0].get_data() \n",
    "mo = xm[np.argmax(ym)]\n",
    "mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f78e6-21de-4b06-8571-00fafd6d812a",
   "metadata": {},
   "source": [
    "Determine what these commands do, then add a vertical bar for each measure of central tendency on top to the KDE plot. If you can't see how to do this, look at the notebook `earth.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbd2f9-2e60-4da6-a742-f293004766b0",
   "metadata": {},
   "source": [
    "Next, compute variance (for an unbiased estimate, use `np.var(x,ddof=1)`), as well as the standard deviation, skewness and kurtosis using Python commands. Some of the tools you need are available in `scipy.stats` (note that `moment(x,n)` computes the $n$-th central moment, but doesn't standardise it). If you know enough python to do so, verify that the computations are correct repeating the them using the basic definitions of these quantities in terms of sums over the data. How would you find the median from the basic definition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc0bec-00a6-4e5b-a943-e116a586b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbiased estimate of the variance\n",
    "np.var(x,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35290fe4-c0f1-4e69-b842-3e94dee397e8",
   "metadata": {},
   "source": [
    "See the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.moment.html#scipy.stats.moment) for `scipy.stats.moment()` and related functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7122c-06b4-420c-b217-6b70216c1e35",
   "metadata": {},
   "source": [
    "## Empirical Cumulative Distribution Function and Survival Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f92cb0-5b1e-4da8-91f6-7f85690381cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that we have imported the ECDF function ...\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# ... then plot the ECDF.\n",
    "ecdf=ECDF(x)\n",
    "plt.step(ecdf.x,ecdf.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f2141-93f1-4e88-9eb3-183b4d07ec38",
   "metadata": {},
   "source": [
    "How would you plot the survival function? To explore the tail of the distribution use the option `plt.yscale('log')`.\n",
    "\n",
    "Finally, find some of the most commonly-reported percentiles percentiles and the interquartile range, and plot them on top the KDE. If you can't see how to do this, look at the notebook `earth.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
